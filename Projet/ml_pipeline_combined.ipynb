{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combined ML Pipeline for Scientific Tweet Analysis\n",
    "\n",
    "Groupe 12\n",
    "Vargas Vila Daniel 22006745\n",
    "Moussa Etienne 22108464\n",
    "Salhi Nina 22115492\n",
    "\n",
    "This notebook combines all three tasks:\n",
    "1. Science Related Classification\n",
    "2. CLAIM/REF vs CONTEXT Classification\n",
    "3. Multi-label Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/daniel/Bureau/ML/Machin\n",
      "[nltk_data]     e_learning/Projet/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/daniel/Bureau/ML/Ma\n",
      "[nltk_data]     chine_learning/Projet/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/daniel/Bureau/ML/Mach\n",
      "[nltk_data]     ine_learning/Projet/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Common imports for all tasks\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import (\n",
    "    classification_report, f1_score, precision_score,\n",
    "    recall_score, accuracy_score, confusion_matrix, make_scorer\n",
    ")\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "import optuna\n",
    "import emoji\n",
    "import re\n",
    "import scipy.sparse\n",
    "import spacy\n",
    "from langdetect import detect\n",
    "import joblib\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "\n",
    "import os\n",
    "# Cr√©ation d'un r√©pertoire local au cas o√π les chemins par d√©faut posent probl√®me\n",
    "nltk_data_dir = os.path.join(os.getcwd(), \"nltk_data\")\n",
    "os.makedirs(nltk_data_dir, exist_ok=True)\n",
    "# Ajout manuel au chemin\n",
    "nltk.data.path.append(nltk_data_dir)\n",
    "nltk.download(\"punkt\", download_dir=nltk_data_dir)\n",
    "nltk.download(\"stopwords\", download_dir=nltk_data_dir)\n",
    "nltk.download(\"wordnet\", download_dir=nltk_data_dir)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD, PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "#Librairies Scikit-learn\n",
    "from sklearn.manifold import TSNE  # R√©duction de dimensions avec T-SNE\n",
    "from sklearn.decomposition import PCA  # R√©duction de dimensions avec ACP\n",
    "\n",
    "from umap import UMAP\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Science Related Classification\n",
    "\n",
    "Pipeline for classifying tweets as science-related or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelPipeline1:\n",
    "    def __init__(self, name=\"ModelPipeline\"):\n",
    "        self.name = name\n",
    "        self.models = {\n",
    "            \"Na√Øve Bayes\": MultinomialNB(),\n",
    "            \"Random Forest\": RandomForestClassifier(n_jobs=-1),\n",
    "            \"SVM\": SVC(kernel='linear'),\n",
    "            \"KNN\": KNeighborsClassifier(n_jobs=-1),\n",
    "            \"AdaBoost\": AdaBoostClassifier(),\n",
    "            \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='logloss', n_jobs=-1),\n",
    "            \"Neural Network - MLP\": MLPClassifier(max_iter=300)\n",
    "        }\n",
    "        self.scorers = {\n",
    "            \"Accuracy\": make_scorer(accuracy_score),\n",
    "            \"Precision\": make_scorer(precision_score),\n",
    "            \"Recall\": make_scorer(recall_score),\n",
    "            \"F1 Score\": make_scorer(f1_score)\n",
    "        }\n",
    "        self.results = {}\n",
    "        self.best_model = None\n",
    "        self.vectorizer = None\n",
    "\n",
    "    def preprocess_data(self, df, with_preprocessing=False):\n",
    "        \"\"\"Preprocess data based on the phase\"\"\"\n",
    "        df['text'] = df['text'].apply(lambda x: emoji.demojize(x))\n",
    "        \n",
    "        df['has_url'] = df['text'].str.contains(r'http[s]?://', regex=True)\n",
    "        df['has_mention'] = df['text'].str.contains(r'@\\w+', regex=True)\n",
    "        df['has_hashtag'] = df['text'].str.contains(r'#\\w+', regex=True)\n",
    "        df['has_emoji'] = df['text'].str.contains(r':[^:\\s]+:')\n",
    "        \n",
    "        if with_preprocessing:\n",
    "            try:\n",
    "                nlp_fr = spacy.load(\"fr_core_news_sm\")\n",
    "                nlp_en = spacy.load(\"en_core_web_sm\")\n",
    "            except OSError:\n",
    "                print(\"Installing spaCy models...\")\n",
    "                import os\n",
    "                os.system(\"python -m spacy download fr_core_news_sm\")\n",
    "                os.system(\"python -m spacy download en_core_web_sm\")\n",
    "                nlp_fr = spacy.load(\"fr_core_news_sm\")\n",
    "                nlp_en = spacy.load(\"en_core_web_sm\")\n",
    "            \n",
    "            def clean_and_lemmatize_multilang(text):\n",
    "                text = text.lower()\n",
    "                text = re.sub(r\"http\\S+\", \"URL\", text)\n",
    "                text = re.sub(r\"@\\w+\", \"MENTION\", text)\n",
    "                text = re.sub(r\"#(\\w+)\", r\"\\1\", text)\n",
    "                text = re.sub(r\"[^\\w\\s:]\", \"\", text)\n",
    "                try:\n",
    "                    lang = detect(text)\n",
    "                except:\n",
    "                    lang = \"en\"\n",
    "                doc = nlp_fr(text) if lang == \"fr\" else nlp_en(text)\n",
    "                return \" \".join([token.lemma_ for token in doc if not token.is_stop])\n",
    "            \n",
    "            df['text_clean'] = df['text'].apply(clean_and_lemmatize_multilang)\n",
    "            text_column = 'text_clean'\n",
    "        else: \n",
    "            text_column = 'text'\n",
    "            \n",
    "        return df, text_column\n",
    "\n",
    "    def prepare_features(self, df, text_column, stopwords=None, max_features=10000):\n",
    "        vectorizer = TfidfVectorizer(\n",
    "            min_df=5,\n",
    "            max_df=0.95,\n",
    "            stop_words=stopwords,\n",
    "            lowercase=True,\n",
    "            ngram_range=(1, 2),\n",
    "            max_features=max_features\n",
    "        ) if stopwords else TfidfVectorizer(max_features=max_features)\n",
    "        \n",
    "        X_text = df[text_column]\n",
    "        X_tfidf = vectorizer.fit_transform(X_text)\n",
    "        self.vectorizer = vectorizer\n",
    "        \n",
    "        extra_features = df[['has_url', 'has_mention', 'has_hashtag', 'has_emoji']].astype(int)\n",
    "        X_extra = scipy.sparse.csr_matrix(extra_features.values)\n",
    "        X_final = scipy.sparse.hstack([X_tfidf, X_extra])\n",
    "        \n",
    "        return X_final, vectorizer\n",
    "\n",
    "    def train_and_evaluate(self, X, y, phase_name):\n",
    "        cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        results = []\n",
    "        best_f1 = 0\n",
    "        \n",
    "        for name, model in self.models.items():\n",
    "            print(f\"\\nüîç Training model: {name}\")\n",
    "            \n",
    "            fold_metrics = {\n",
    "                \"Accuracy\": [],\n",
    "                \"Precision\": [],\n",
    "                \"Recall\": [],\n",
    "                \"F1\": []\n",
    "            }\n",
    "            \n",
    "            for fold, (train_idx, test_idx) in enumerate(cv.split(X.toarray() if scipy.sparse.issparse(X) else X, y), 1):\n",
    "                X_train, X_test = X[train_idx], X[test_idx]\n",
    "                y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "                \n",
    "                model.fit(X_train, y_train)\n",
    "                y_pred = model.predict(X_test)\n",
    "                \n",
    "                fold_metrics[\"Accuracy\"].append(accuracy_score(y_test, y_pred))\n",
    "                fold_metrics[\"Precision\"].append(precision_score(y_test, y_pred))\n",
    "                fold_metrics[\"Recall\"].append(recall_score(y_test, y_pred))\n",
    "                fold_metrics[\"F1\"].append(f1_score(y_test, y_pred))\n",
    "                \n",
    "                if fold == cv.n_splits:\n",
    "                    plt.figure(figsize=(6, 5))\n",
    "                    sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='Blues')\n",
    "                    plt.title(f'Confusion Matrix - {name} ({phase_name})')\n",
    "                    plt.xlabel('Predicted')\n",
    "                    plt.ylabel('True')\n",
    "                    plt.show()\n",
    "            \n",
    "            metrics = {\n",
    "                \"Model\": name,\n",
    "                \"Phase\": phase_name\n",
    "            }\n",
    "            \n",
    "            for metric_name, scores in fold_metrics.items():\n",
    "                metrics[metric_name] = np.mean(scores)\n",
    "                metrics[f\"{metric_name}_Std\"] = np.std(scores)\n",
    "                print(f\"{metric_name}: {np.mean(scores):.4f} ¬± {np.std(scores):.4f}\")\n",
    "            \n",
    "            if metrics[\"F1\"] > best_f1:\n",
    "                best_f1 = metrics[\"F1\"]\n",
    "                self.best_model = {\n",
    "                    'name': name,\n",
    "                    'model': model,\n",
    "                    'vectorizer': self.vectorizer\n",
    "                }\n",
    "            \n",
    "            results.append(metrics)\n",
    "        \n",
    "        results_df = pd.DataFrame(results)\n",
    "        results_df.to_csv(f'model_results_task1_{phase_name.lower().replace(\" \", \"_\")}.csv', index=False)\n",
    "        return results_df\n",
    "\n",
    "    def save_best_model(self):\n",
    "        if self.best_model is None:\n",
    "            print(\"No best model found. Please run train_and_evaluate first.\")\n",
    "            return\n",
    "        \n",
    "        print(f\"\\nSaving best model: {self.best_model['name']}\")\n",
    "        joblib.dump(self.best_model, 'best_model_task1.joblib')\n",
    "        print(\"Model saved successfully!\")\n",
    "\n",
    "    def optimize_mlp_with_optuna(self, X, y, n_trials=30):\n",
    "        def objective(trial):\n",
    "            hidden_layer_sizes = trial.suggest_categorical(\n",
    "                \"hidden_layer_sizes\", [(50,), (100,), (50, 50), (100, 50)]\n",
    "            )\n",
    "            learning_rate_init = trial.suggest_float(\"learning_rate_init\", 1e-4, 1e-1, log=True)\n",
    "    \n",
    "            model = Pipeline([\n",
    "                (\"scaler\", StandardScaler(with_mean=False)),\n",
    "                (\"mlp\", MLPClassifier(\n",
    "                    hidden_layer_sizes=hidden_layer_sizes,\n",
    "                    learning_rate_init=learning_rate_init,\n",
    "                    max_iter=500,\n",
    "                    random_state=42\n",
    "                ))\n",
    "            ])\n",
    "    \n",
    "            # Cross-validation\n",
    "            cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "            scores = cross_val_score(model, X, y, cv=cv, scoring=\"accuracy\")\n",
    "            return scores.mean()\n",
    "\n",
    "def run_task1():\n",
    "    \"\"\"Execute Task 1: Science Related Classification\"\"\"\n",
    "    print(\"\\n=== Task 1: Science Related Classification ===\")\n",
    "    \n",
    "    # Load data\n",
    "    print(\"\\nLoading data...\")\n",
    "    df = pd.read_csv('scitweets_balanced.tsv', sep='\\t')\n",
    "    df.dropna(subset=['text'], inplace=True)\n",
    "    y = df['science_related']\n",
    "    \n",
    "    # Initialize and run pipeline\n",
    "    pipeline = ModelPipeline1()\n",
    "    print(\"\\n=== Training Model ===\")\n",
    "    df_prepared, text_column = pipeline.preprocess_data(df.copy(), with_preprocessing=True)\n",
    "    \n",
    "    # Load French stopwords\n",
    "    stopwords_df = pd.read_csv(\"StopWordsFrench.csv\", sep=',', index_col=0)\n",
    "    french_stopwords = stopwords_df.index.tolist()\n",
    "    \n",
    "    # Prepare features and train\n",
    "    X_prepared, _ = pipeline.prepare_features(df_prepared, text_column, french_stopwords)\n",
    "    results = pipeline.optimize_mlp_with_optuna(X_prepared, y, \"Full_Training\")\n",
    "    \n",
    "    # Save the best model\n",
    "    pipeline.save_best_model()\n",
    "    \n",
    "    # Plot final results\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    metrics = ['Accuracy', 'Precision', 'Recall', 'F1']\n",
    "    for i, metric in enumerate(metrics, 1):\n",
    "        plt.subplot(1, 4, i)\n",
    "        sns.barplot(data=results, x='Model', y=metric)\n",
    "        plt.title(f'{metric} Comparison')\n",
    "        plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: CLAIM/REF vs CONTEXT Classification\n",
    "\n",
    "Pipeline for classifying tweets between CLAIM/REF and CONTEXT categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelPipeline2:\n",
    "    def __init__(self, name=\"ModelPipeline\"):\n",
    "        self.name = name\n",
    "        self.models = {\n",
    "            \"Logistic Regression\": LogisticRegression(max_iter=500),\n",
    "            \"Multinomial NB\": MultinomialNB(),\n",
    "            \"Random Forest\": RandomForestClassifier(),\n",
    "            \"SVM\": SVC(),\n",
    "            \"SVM linear\": LinearSVC(),\n",
    "            \"KNN\": KNeighborsClassifier(),\n",
    "            \"AdaBoost\": AdaBoostClassifier(),\n",
    "            \"Gradient Boosting\": GradientBoostingClassifier(random_state=42),\n",
    "            \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='logloss'),\n",
    "            \"Neural Network - MLP\": MLPClassifier(max_iter=300)\n",
    "        }\n",
    "        self.scorers = {\n",
    "            \"Accuracy\": make_scorer(accuracy_score),\n",
    "            \"Precision\": make_scorer(precision_score),\n",
    "            \"Recall\": make_scorer(recall_score),\n",
    "            \"F1 Score\": make_scorer(f1_score)\n",
    "        }\n",
    "        self.results = {}\n",
    "        self.best_model = None\n",
    "        self.vectorizer = None\n",
    "\n",
    "    def clean_text_light(self, text):\n",
    "        text = text.lower()\n",
    "        text = re.sub(r\"http\\S+\", \"URL\", text)\n",
    "        text = re.sub(r\"@\\w+\", \"MENTION\", text)\n",
    "        text = re.sub(r\"#(\\w+)\", r\"\\1\", text)\n",
    "        text = re.sub(r\":[^:\\s]+:\", \"EMOJI\", text)\n",
    "        return text\n",
    "\n",
    "    def analyze_data(self, df):\n",
    "        df_sci = df[df[\"science_related\"] == 1]\n",
    "\n",
    "        df_context = df_sci[df_sci[\"scientific_context\"] == 1.0]\n",
    "        df_context_unic = df_context[(df_context[\"scientific_claim\"] == 0.0) & (df_context[\"scientific_reference\"] == 0.0)]\n",
    "        df_claim_ref = df_sci[(df_sci[\"scientific_claim\"] == 1.0) & (df_sci[\"scientific_reference\"] == 1.0)]\n",
    "        df_claim_ou_ref = df_sci[(df_sci[\"scientific_claim\"] == 1.0) | (df_sci[\"scientific_reference\"] == 1.0)]\n",
    "        df_claim_ou_ref_unic = df_claim_ou_ref[df_claim_ou_ref[\"scientific_context\"] == 0.0]\n",
    "        df_claim_ref_context = df_sci[\n",
    "            (df_sci[\"scientific_claim\"] == 1.0) & \n",
    "            (df_sci[\"scientific_reference\"] == 1.0) & \n",
    "            (df_sci[\"scientific_context\"] == 1.0)\n",
    "        ]\n",
    "\n",
    "        counts = {\n",
    "            \"CLAIM ou REF (avec context possible)\": len(df_claim_ou_ref),\n",
    "            \"CLAIM ou REF (sans context)\": len(df_claim_ou_ref_unic),\n",
    "            \"CONTEXT uniquement (sans claim ou ref)\": len(df_context_unic),\n",
    "            \"CONTEXT (avec claim ou ref)\": len(df_context),\n",
    "            \"CLAIM et REF et CONTEXT\": len(df_claim_ref_context)\n",
    "        }\n",
    "\n",
    "        df_counts = pd.DataFrame(list(counts.items()), columns=[\"Cat√©gorie\", \"Nombre\"])\n",
    "\n",
    "        plt.figure(figsize=(11, 7))\n",
    "        bars = plt.bar(df_counts[\"Cat√©gorie\"], df_counts[\"Nombre\"], color=[\"#4C72B0\", \"#55A868\", \"#C44E52\", \"#8172B3\", \"#E9967A\"])\n",
    "        plt.title(\"R√©partition des types d'assertions scientifiques\", fontsize=14)\n",
    "        plt.xlabel(\"Type d'assertion\", fontsize=12)\n",
    "        plt.ylabel(\"Nombre de tweets\", fontsize=12)\n",
    "        plt.xticks(rotation=15)\n",
    "        plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "        for bar in bars:\n",
    "            yval = bar.get_height()\n",
    "            plt.text(bar.get_x() + bar.get_width()/2, yval + 5, int(yval), ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        return df_sci\n",
    "\n",
    "    def create_label(self, df_sci):\n",
    "        df_sci = df_sci.copy()\n",
    "        df_sci[\"label\"] = df_sci.apply(\n",
    "            lambda row: 0 if (row[\"scientific_context\"] == 1.0 and \n",
    "                             row[\"scientific_claim\"] == 0.0 and \n",
    "                             row[\"scientific_reference\"] == 0.0)\n",
    "            else 1,\n",
    "            axis=1\n",
    "        )\n",
    "        print(\"\\n Label distribution:\")\n",
    "        print(df_sci[\"label\"].value_counts())\n",
    "        return df_sci\n",
    "\n",
    "    def MyCleanText(self, X,\n",
    "                    lowercase=True,\n",
    "                    removestopwords=False,\n",
    "                    removedigit=True,\n",
    "                    getstemmer=False,\n",
    "                    getlemmatisation=True,\n",
    "                    stop_words=None):\n",
    "\n",
    "        sentence = str(X)\n",
    "        sentence = re.sub(r'[^\\w\\s]', ' ', sentence)\n",
    "        sentence = re.sub(r'\\s+', ' ', sentence, flags=re.I)\n",
    "\n",
    "        tokens = word_tokenize(sentence)\n",
    "\n",
    "        if lowercase:\n",
    "            tokens = [token.lower() for token in tokens]\n",
    "        tokens = [word for word in tokens if word.isalnum()]\n",
    "\n",
    "        if removedigit:\n",
    "            tokens = [word for word in tokens if not word.isdigit()]\n",
    "\n",
    "        if removestopwords and stop_words is not None:\n",
    "            tokens = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "        if getlemmatisation:\n",
    "            lemmatizer = WordNetLemmatizer()\n",
    "            tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "\n",
    "        if getstemmer:\n",
    "            ps = PorterStemmer()\n",
    "            tokens = [ps.stem(word) for word in tokens]\n",
    "\n",
    "        return ' '.join(tokens)\n",
    "\n",
    "    def preprocess_data(self, df, use_advanced_cleaning=False):\n",
    "        df['tweet_text'] = df['text'].apply(lambda x: emoji.demojize(x))\n",
    "\n",
    "        df['has_url'] = df['text'].str.contains(r'http[s]?://', regex=True)\n",
    "        df['has_mention'] = df['text'].str.contains(r'@\\w+', regex=True)\n",
    "        df['has_hashtag'] = df['text'].str.contains(r'#\\w+', regex=True)\n",
    "        df['has_emoji'] = df['tweet_text'].str.contains(r':[^:\\s]+:', regex=True)\n",
    "\n",
    "        if use_advanced_cleaning:\n",
    "            print(\"üßπ Nettoyage avanc√© + lemmatisation...\")\n",
    "            df['text_clean'] = df['tweet_text'].apply(self.clean_text_light)\n",
    "            stop_words = set(stopwords.words('english'))\n",
    "            df['text_clean'] = df['text_clean'].apply(lambda x: self.MyCleanText(\n",
    "                x,\n",
    "                lowercase=True,\n",
    "                removestopwords=False,\n",
    "                removedigit=True,\n",
    "                getstemmer=False,\n",
    "                getlemmatisation=True,\n",
    "                stop_words=stop_words\n",
    "            ))\n",
    "        else:\n",
    "            print(\"üßΩ Nettoyage simple (light)...\")\n",
    "            df['text_clean'] = df['tweet_text'].apply(self.clean_text_light)\n",
    "\n",
    "        df.dropna(subset=['text_clean'], inplace=True)\n",
    "        return df, 'text_clean'\n",
    "\n",
    "    def add_text_features(self, df):\n",
    "        df['tweet_text'] = df['text'].apply(lambda x: emoji.demojize(x))\n",
    "        df['has_url'] = df['text'].str.contains(r'http[s]?://', regex=True)\n",
    "        df['has_mention'] = df['text'].str.contains(r'@\\w+', regex=True)\n",
    "        df['has_hashtag'] = df['text'].str.contains(r'#\\w+', regex=True)\n",
    "        df['has_emoji'] = df['tweet_text'].str.contains(r':[^:\\s]+:', regex=True)\n",
    "        return df\n",
    "\n",
    "    def vectorize_text(self, df, use_cleaned=False):\n",
    "        text_column = 'text_clean' if use_cleaned and 'text_clean' in df.columns else 'tweet_text'\n",
    "        df = df.dropna(subset=[text_column])\n",
    "        X_text = df[text_column]\n",
    "\n",
    "        vectorizer = TfidfVectorizer(\n",
    "            lowercase=True,\n",
    "            stop_words='english',\n",
    "            ngram_range=(1, 2),\n",
    "            max_df=0.9,\n",
    "            min_df=2\n",
    "        )\n",
    "        X_tfidf = vectorizer.fit_transform(X_text)\n",
    "        self.vectorizer = vectorizer\n",
    "\n",
    "        extra_features = df[['has_url', 'has_mention', 'has_hashtag']].astype(int)\n",
    "        X_extra = scipy.sparse.csr_matrix(extra_features.values)\n",
    "\n",
    "        X_full = scipy.sparse.hstack([X_tfidf, X_extra])\n",
    "        print(\"üî¢ Taille TF-IDF :\", X_tfidf.shape)\n",
    "        print(\"‚ûï Taille features binaires :\", X_extra.shape)\n",
    "        print(\"üìê Taille finale :\", X_full.shape)\n",
    "\n",
    "        return X_tfidf, X_full, vectorizer\n",
    "\n",
    "    def extract_cleaned_features(self, X_tfidf, vectorizer):\n",
    "        feature_names = vectorizer.get_feature_names_out()\n",
    "        tfidf_df = pd.DataFrame(X_tfidf.toarray(), columns=feature_names)\n",
    "\n",
    "        def get_token_category(token):\n",
    "            if token.isdigit():\n",
    "                return 'numeric'\n",
    "            if re.match(r'^\\d+(am|pm|s|h|min|sec|hour|years)?$', token.lower()):\n",
    "                return 'timestamp'\n",
    "            if re.match(r'^[a-zA-Z]+$', token):\n",
    "                return 'valid'\n",
    "            return 'other'\n",
    "\n",
    "        token_categories = {token: get_token_category(token) for token in tfidf_df.columns}\n",
    "        valid_tokens = [t for t, c in token_categories.items() if c == 'valid']\n",
    "        numeric_tokens = [t for t, c in token_categories.items() if c == 'numeric']\n",
    "        timestamp_tokens = [t for t, c in token_categories.items() if c == 'timestamp']\n",
    "\n",
    "        tfidf_df['numeric'] = tfidf_df[numeric_tokens].sum(axis=1) if numeric_tokens else 0\n",
    "        tfidf_df['timestamp'] = tfidf_df[timestamp_tokens].sum(axis=1) if timestamp_tokens else 0\n",
    "        tfidf_cleaned = tfidf_df[valid_tokens + ['numeric', 'timestamp']]\n",
    "        X_cleaned = scipy.sparse.csr_matrix(tfidf_cleaned.values)\n",
    "\n",
    "        print(\"üßº Matrice nettoy√©e :\", tfidf_cleaned.shape)\n",
    "        return X_cleaned, tfidf_cleaned\n",
    "\n",
    "    def evaluate_models(self, X, y):\n",
    "        models = {\n",
    "            \"Logistic Regression\": LogisticRegression(max_iter=500),\n",
    "            \"Multinomial NB\": MultinomialNB(),\n",
    "            \"Random Forest\": RandomForestClassifier(),\n",
    "            \"SVM\": SVC(),\n",
    "            \"SVM linear\": LinearSVC(),\n",
    "            \"KNN\": KNeighborsClassifier(),\n",
    "            \"AdaBoost\": AdaBoostClassifier(),\n",
    "            \"Gradient Boosting\": GradientBoostingClassifier(random_state=42),\n",
    "            \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='logloss'),\n",
    "            \"Neural Network (MLP)\": MLPClassifier(max_iter=300)\n",
    "        }\n",
    "\n",
    "        skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        results = []\n",
    "\n",
    "        scoring_metrics = {\n",
    "            'Accuracy': make_scorer(accuracy_score),\n",
    "            'Precision': make_scorer(precision_score),\n",
    "            'Recall': make_scorer(recall_score),\n",
    "            'F1': make_scorer(f1_score)\n",
    "        }\n",
    "\n",
    "        for name, model in models.items():\n",
    "            row = {'Model': name}\n",
    "            for metric_name, scorer in scoring_metrics.items():\n",
    "                scores = cross_val_score(model, X, y, cv=skf, scoring=scorer)\n",
    "                row[metric_name] = f\"{scores.mean():.3f} ¬± {scores.std():.3f}\"\n",
    "            results.append(row)\n",
    "\n",
    "        results_df = pd.DataFrame(results)\n",
    "        results_df = results_df.sort_values(by=\"F1\", ascending=False)\n",
    "        print(\"üìä R√©sultats de la validation crois√©e (tri√©s par F1) :\")\n",
    "        display(results_df)\n",
    "        return results_df\n",
    "\n",
    "def run_task2():\n",
    "    \"\"\"Execute Task 2: CLAIM/REF vs CONTEXT Classification\"\"\"\n",
    "    print(\"\\n=== Task 2: CLAIM/REF vs CONTEXT Classification ===\")\n",
    "    \n",
    "    # Load data\n",
    "    print(\"\\nLoading data...\")\n",
    "    df = pd.read_csv('scitweets_export_tache2_60_40.tsv', sep='\\t')\n",
    "    \n",
    "    # Initialize and run pipeline\n",
    "    pipeline = ModelPipeline2()\n",
    "    \n",
    "    # Process data\n",
    "    df_sci = pipeline.analyze_data(df)\n",
    "    df_sci = pipeline.create_label(df_sci)\n",
    "    df_sci, text_column = pipeline.preprocess_data(df_sci, use_advanced_cleaning=True)\n",
    "    \n",
    "    # Create features\n",
    "    X_tfidf, X_full, vect = pipeline.vectorize_text(df_sci, use_cleaned=True)\n",
    "    X_cleaned, _ = pipeline.extract_cleaned_features(X_tfidf, vect)\n",
    "    y = df_sci[\"label\"]\n",
    "    \n",
    "    # Train and evaluate\n",
    "    print(\"\\n=== Training Models ===\")\n",
    "    results_df = pipeline.evaluate_models(X_cleaned, y)\n",
    "    \n",
    "    # Display results\n",
    "    print(\"\\nüìä Model Performance Results (sorted by F1 score):\")\n",
    "    display(results_df)\n",
    "    \n",
    "    # Plot results\n",
    "    plot_df = results_df[[\"Accuracy\", \"Precision\", \"Recall\", \"F1\"]].copy()\n",
    "\n",
    "    for metric in [\"Accuracy\", \"Precision\", \"Recall\", \"F1\"]:\n",
    "        plot_df[metric] = results_df[metric].astype(str).str.extract(r\"([\\d\\.]+)\").astype(float)\n",
    "    \n",
    "    plot_df.index = results_df[\"Model\"]\n",
    "    \n",
    "    plot_df.plot(kind='bar', figsize=(12, 6))\n",
    "    \n",
    "    plt.title(\"üìä Performances des mod√®les sur le Test Set\", fontsize=14)\n",
    "    plt.xlabel(\"Mod√®le\", fontsize=12)\n",
    "    plt.ylabel(\"Score\", fontsize=12)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.legend(title=\"M√©trique\", loc=\"lower right\")\n",
    "    plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import optuna.visualization as vis\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_predict, cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score, make_scorer\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "class HyperparameterTuner:\n",
    "    def __init__(self):\n",
    "        self.best_models = {}\n",
    "\n",
    "    def tune_and_evaluate(self, model_name, model, param_grid, X, y):\n",
    "        print(f\"\\nüîç Recherche d'hyperparam√®tres pour {model_name}...\")\n",
    "        search = GridSearchCV(model, param_grid=param_grid, scoring='f1', cv=5)\n",
    "        search.fit(X, y)\n",
    "\n",
    "        print(f\"‚úÖ Meilleurs param√®tres {model_name} :\", search.best_params_)\n",
    "\n",
    "        y_pred = cross_val_predict(search.best_estimator_, X, y, cv=5)\n",
    "\n",
    "        print(f\"\\nüìä Rapport de classification - {model_name} (validation crois√©e) :\")\n",
    "        print(classification_report(y, y_pred))\n",
    "\n",
    "        self.best_models[model_name] = search.best_estimator_\n",
    "\n",
    "    def tune_all(self, X, y):\n",
    "        param_svm = {\n",
    "            'C': [0.01, 0.1, 1, 10]\n",
    "        }\n",
    "        self.tune_and_evaluate(\"SVM (lin√©aire)\", LinearSVC(), param_svm, X, y)\n",
    "\n",
    "        param_mlp = {\n",
    "            'hidden_layer_sizes': [(100,), (100,50)],\n",
    "            'alpha': [0.0001, 0.001],\n",
    "            'learning_rate_init': [0.001, 0.01]\n",
    "        }\n",
    "        self.tune_and_evaluate(\"MLP\", MLPClassifier(max_iter=300, random_state=42), param_mlp, X, y)\n",
    "\n",
    "        param_nb = {\n",
    "            'alpha': [0.1, 0.5, 1.0]\n",
    "        }\n",
    "        self.tune_and_evaluate(\"Multinomial NB\", MultinomialNB(), param_nb, X, y)\n",
    "\n",
    "    def get_best_model(self, name):\n",
    "        return self.best_models.get(name, None)\n",
    "\n",
    "    def evaluate_model_cv(self, model, X, y, cv=5):\n",
    "        accs, precs, recalls, f1s = [], [], [], []\n",
    "        skf = StratifiedKFold(n_splits=cv, shuffle=True, random_state=42)\n",
    "\n",
    "        for train_idx, test_idx in skf.split(X, y):\n",
    "            X_train, X_test = X[train_idx], X[test_idx]\n",
    "            y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_test)\n",
    "\n",
    "            accs.append(accuracy_score(y_test, y_pred))\n",
    "            precs.append(precision_score(y_test, y_pred))\n",
    "            recalls.append(recall_score(y_test, y_pred))\n",
    "            f1s.append(f1_score(y_test, y_pred))\n",
    "\n",
    "        print(\"\\nüî¨ R√©sultats avec CV (moyenne ¬± √©cart-type):\")\n",
    "        print(f\"Accuracy : {np.mean(accs):.3f} ¬± {np.std(accs):.3f}\")\n",
    "        print(f\"Precision: {np.mean(precs):.3f} ¬± {np.std(precs):.3f}\")\n",
    "        print(f\"Recall   : {np.mean(recalls):.3f} ¬± {np.std(recalls):.3f}\")\n",
    "        print(f\"F1-score : {np.mean(f1s):.3f} ¬± {np.std(f1s):.3f}\")\n",
    "\n",
    "    def run_optuna(self, X, y, model_choisi):\n",
    "        skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "        def objective_svm(trial):\n",
    "            C = trial.suggest_float(\"C\", 1e-3, 10, log=True)\n",
    "            clf = LinearSVC(C=C, max_iter=1000)\n",
    "            scores = cross_val_score(clf, X, y, cv=skf, scoring='f1')\n",
    "            return scores.mean()\n",
    "\n",
    "        def objective_svc(trial):\n",
    "            kernel = trial.suggest_categorical('kernel', ['linear', 'rbf', 'poly', 'sigmoid'])\n",
    "            params = {\n",
    "                'C': trial.suggest_float('C', 1e-2, 10, log=True),\n",
    "                'kernel': kernel,\n",
    "                'gamma': trial.suggest_categorical('gamma', ['scale', 'auto'])\n",
    "            }\n",
    "            if kernel == 'poly':\n",
    "                params['degree'] = trial.suggest_int('degree', 2, 5)\n",
    "            model = SVC(**params)\n",
    "            scores = cross_val_score(model, X, y, cv=skf, scoring='f1', n_jobs=-1)\n",
    "            return scores.mean()\n",
    "\n",
    "        def objective_mlp(trial):\n",
    "            hidden_layer_sizes = trial.suggest_categorical(\"hidden_layer_sizes\", [(100,), (100, 50), (150,)])\n",
    "            alpha = trial.suggest_float(\"alpha\", 1e-5, 1e-2, log=True)\n",
    "            learning_rate_init = trial.suggest_float(\"learning_rate_init\", 1e-4, 1e-1, log=True)\n",
    "            clf = make_pipeline(\n",
    "                StandardScaler(with_mean=False),\n",
    "                MLPClassifier(hidden_layer_sizes=hidden_layer_sizes, alpha=alpha,\n",
    "                             learning_rate_init=learning_rate_init, max_iter=300, random_state=42)\n",
    "            )\n",
    "            scores = cross_val_score(clf, X, y, cv=skf, scoring='f1')\n",
    "            return scores.mean()\n",
    "\n",
    "        def objective_mlp2(trial):\n",
    "            hidden_layer_sizes = (\n",
    "                trial.suggest_int('hidden_layer_1', 50, 200),\n",
    "                trial.suggest_int('hidden_layer_2', 0, 150)\n",
    "            )\n",
    "            hidden_layer_sizes = tuple([h for h in hidden_layer_sizes if h > 0])\n",
    "            clf = make_pipeline(\n",
    "                StandardScaler(with_mean=False),\n",
    "                MLPClassifier(\n",
    "                    hidden_layer_sizes=hidden_layer_sizes,\n",
    "                    learning_rate_init=trial.suggest_float('learning_rate_init', 0.0001, 0.1, log=True),\n",
    "                    activation=trial.suggest_categorical('activation', ['relu', 'tanh']),\n",
    "                    alpha=trial.suggest_float('alpha', 1e-5, 1e-1, log=True),\n",
    "                    max_iter=300, random_state=42\n",
    "                )\n",
    "            )\n",
    "            scores = cross_val_score(clf, X, y, cv=skf, scoring='f1', n_jobs=-1)\n",
    "            return scores.mean()\n",
    "\n",
    "        def objective_nb(trial):\n",
    "            alpha = trial.suggest_float(\"alpha\", 1e-3, 2.0, log=True)\n",
    "            clf = MultinomialNB(alpha=alpha)\n",
    "            scores = cross_val_score(clf, X, y, cv=skf, scoring='f1')\n",
    "            return scores.mean()\n",
    "        \n",
    "        if model_choisi==\"svm\" :\n",
    "            \n",
    "            # SVM\n",
    "            study_svm = optuna.create_study(direction=\"maximize\")\n",
    "            study_svm.optimize(objective_svm, n_trials=200)\n",
    "            print(\"\\nüîç Best params SVM:\", study_svm.best_params)\n",
    "            print(\"ü•á Best F1 score SVM:\", study_svm.best_value)\n",
    "            best_svm = LinearSVC(C=study_svm.best_params[\"C\"], random_state=42)\n",
    "            self.evaluate_model_cv(best_svm, X, y)\n",
    "            vis.plot_optimization_history(study_svm).show()\n",
    "            vis.plot_param_importances(study_svm).show()\n",
    "\n",
    "        if model_choisi==\"svc\" :\n",
    "\n",
    "            # SVC\n",
    "            study_svc = optuna.create_study(direction=\"maximize\")\n",
    "            study_svc.optimize(objective_svc, n_trials=200)\n",
    "            params = study_svc.best_params.copy()\n",
    "            if params['kernel'] != 'poly' and 'degree' in params:\n",
    "                del params['degree']\n",
    "            best_svc = SVC(**params)\n",
    "            print(\"\\nüîç Best SVC params:\", params)\n",
    "            print(\"ü•á Best F1 score SVC:\", study_svc.best_value)\n",
    "            self.evaluate_model_cv(best_svc, X, y)\n",
    "            vis.plot_optimization_history(study_svc).show()\n",
    "            vis.plot_param_importances(study_svc).show()\n",
    "\n",
    "        if model_choisi==\"mlp1\" :\n",
    "\n",
    "            # MLP (v1)\n",
    "            study_mlp = optuna.create_study(direction=\"maximize\")\n",
    "            study_mlp.optimize(objective_mlp, n_trials=50)\n",
    "            print(\"\\nüîç Best MLP params:\", study_mlp.best_params)\n",
    "            print(\"ü•á Best F1 score MLP:\", study_mlp.best_value)\n",
    "            best_mlp = make_pipeline(\n",
    "                StandardScaler(with_mean=False),\n",
    "                MLPClassifier(**study_mlp.best_params, max_iter=300, random_state=42)\n",
    "            )\n",
    "            self.evaluate_model_cv(best_mlp, X, y)\n",
    "            vis.plot_optimization_history(study_mlp).show()\n",
    "            vis.plot_param_importances(study_mlp).show()\n",
    "\n",
    "        if model_choisi==\"mlp2\" :\n",
    "\n",
    "            # MLP (v2)\n",
    "            study_mlp2 = optuna.create_study(direction=\"maximize\")\n",
    "            study_mlp2.optimize(objective_mlp2, n_trials=50)\n",
    "            params = study_mlp2.best_params\n",
    "            hidden_layer_sizes = []\n",
    "            if 'hidden_layer_1' in params:\n",
    "                hidden_layer_sizes.append(params['hidden_layer_1'])\n",
    "            if 'hidden_layer_2' in params and params['hidden_layer_2'] > 0:\n",
    "                hidden_layer_sizes.append(params['hidden_layer_2'])\n",
    "            best_mlp2 = make_pipeline(\n",
    "                StandardScaler(with_mean=False),\n",
    "                MLPClassifier(\n",
    "                    hidden_layer_sizes=tuple(hidden_layer_sizes),\n",
    "                    learning_rate_init=params['learning_rate_init'],\n",
    "                    activation=params['activation'],\n",
    "                    alpha=params['alpha'],\n",
    "                    max_iter=300,\n",
    "                    random_state=42\n",
    "                )\n",
    "            )\n",
    "            print(\"\\nüîç Study 2 - Best MLP params:\", params)\n",
    "            print(\"ü•á Study 2 - Best F1 score MLP:\", study_mlp2.best_value)\n",
    "            self.evaluate_model_cv(best_mlp2, X, y)\n",
    "            vis.plot_optimization_history(study_mlp2).show()\n",
    "            vis.plot_param_importances(study_mlp2).show()\n",
    "\n",
    "        if model_choisi==\"mb\" :\n",
    "            study_nb = optuna.create_study(direction=\"maximize\")\n",
    "            study_nb.optimize(objective_nb, n_trials=200)\n",
    "            print(\"\\nüîç Best MultinomialNB params:\", study_nb.best_params)\n",
    "            print(\"ü•á Best F1 score MultinomialNB:\", study_nb.best_value)\n",
    "            best_nb = MultinomialNB(**study_nb.best_params)\n",
    "            self.evaluate_model_cv(best_nb, X, y)\n",
    "            vis.plot_optimization_history(study_nb).show()\n",
    "            vis.plot_param_importances(study_nb).show()\n",
    "\n",
    "def run_hyper():\n",
    "    tuner = HyperparameterTuner()\n",
    "    #tuner.tune_all(X_cleaned, y) \n",
    "    \n",
    "    #best_mlp = tuner.get_best_model(\"MLP\")\n",
    "    \n",
    "    tuner.run_optuna(X_cleaned, y, \"svc\")\n",
    "    tuner.run_optuna(X_cleaned, y, \"svm\") \n",
    "    tuner.run_optuna(X_cleaned, y, \"mb\") \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD, PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.manifold import TSNE\n",
    "from umap import UMAP\n",
    "\n",
    "class DataVisualizer:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def reduce_dimensions(self, X, method=\"svd\"):\n",
    "        if method == \"svd\":\n",
    "            reducer = TruncatedSVD(n_components=2, random_state=42)\n",
    "        else:\n",
    "            reducer = PCA(n_components=2, random_state=42)\n",
    "\n",
    "        return reducer.fit_transform(X)\n",
    "\n",
    "    def plot_decision_boundary(self, model, X_2D, y, title):\n",
    "        h = .02\n",
    "        x_min, x_max = X_2D[:, 0].min() - 1, X_2D[:, 0].max() + 1\n",
    "        y_min, y_max = X_2D[:, 1].min() - 1, X_2D[:, 1].max() + 1\n",
    "        xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "\n",
    "        model.fit(X_2D, y)\n",
    "        try:\n",
    "            Z = model.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
    "        except Exception as e:\n",
    "            print(f\"Erreur: {e}\")\n",
    "            return\n",
    "\n",
    "        cmap_light = ListedColormap(['#FFCCCC', '#CCCCFF'])\n",
    "        cmap_bold = ListedColormap(['#FF0000', '#0000FF'])\n",
    "\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        plt.contourf(xx, yy, Z, cmap=cmap_light, alpha=0.3)\n",
    "        plt.scatter(X_2D[:, 0], X_2D[:, 1], c=y, cmap=cmap_bold, edgecolor='k', s=20)\n",
    "        plt.title(f\"Fronti√®re de d√©cision : {title}\")\n",
    "        plt.xlabel(\"Composante 1\")\n",
    "        plt.ylabel(\"Composante 2\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def plot_multiple_boundaries(self, X, y):\n",
    "        pca = PCA(n_components=2, random_state=42)\n",
    "        X_vis = pca.fit_transform(X.toarray())\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(X_vis)\n",
    "\n",
    "        classifiers = {\n",
    "            \"Logistic Regression\": LogisticRegression(),\n",
    "            \"Gaussian NB\": GaussianNB(),\n",
    "            \"KNN\": KNeighborsClassifier(),\n",
    "            \"SVM\": SVC()\n",
    "        }\n",
    "\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "        axes = axes.ravel()\n",
    "        colors = ['blue', 'orange']\n",
    "        markers = ['o', 's']\n",
    "\n",
    "        for idx, (name, clf) in enumerate(classifiers.items()):\n",
    "            clf.fit(X_scaled, y)\n",
    "            accuracy = clf.score(X_scaled, y)\n",
    "\n",
    "            DecisionBoundaryDisplay.from_estimator(\n",
    "                clf, X_scaled, cmap=plt.cm.Paired, response_method=\"predict\", alpha=0.8, ax=axes[idx]\n",
    "            )\n",
    "\n",
    "            for label, marker, color in zip([0, 1], markers, colors):\n",
    "                axes[idx].scatter(X_scaled[y == label][:, 0], X_scaled[y == label][:, 1],\n",
    "                                  c=color, marker=marker, edgecolor='k', label=f\"Classe {label}\" if idx == 0 else \"\")\n",
    "\n",
    "            axes[idx].set_title(f\"{name} (Accuracy: {accuracy:.2f})\", fontsize=12)\n",
    "            axes[idx].set_xlabel(\"PC1\")\n",
    "            axes[idx].set_ylabel(\"PC2\")\n",
    "\n",
    "        handles = [plt.Line2D([0], [0], marker=markers[i], color='w', markerfacecolor=colors[i], markeredgecolor='k', markersize=10, label=f\"Classe {i}\") for i in range(2)]\n",
    "        fig.legend(handles=handles, loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "        plt.tight_layout(rect=[0, 0, 0.85, 1])\n",
    "        plt.show()\n",
    "\n",
    "    def plot_roc_curve(self, y_true, y_scores, model_name=\"Model\"):\n",
    "        fpr, tpr, thresholds = roc_curve(y_true, y_scores)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.plot(fpr, tpr, marker='o', linestyle='-', color='blue', label=f'ROC curve (AUC = {roc_auc:.3f})')\n",
    "        plt.plot([0, 1], [0, 1], color='red', linestyle='--', label='Random classifier')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate (FPR)')\n",
    "        plt.ylabel('True Positive Rate (TPR)')\n",
    "        plt.title(f'ROC Curve - {model_name}')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "    def plot_dimensionality_reduction(self, X, y):\n",
    "        df_y = pd.Series(y).astype(str)\n",
    "        X_dense = X.toarray()\n",
    "\n",
    "        # PCA 2D\n",
    "        pca = PCA(n_components=2, random_state=0)\n",
    "        components_2d = pca.fit_transform(X_dense)\n",
    "        fig_pca_2d = px.scatter(pd.DataFrame(components_2d), x=0, y=1, color=df_y, labels={\"color\": \"Label\"})\n",
    "        fig_pca_2d.update_layout(title='ACP (2D)')\n",
    "        fig_pca_2d.show()\n",
    "\n",
    "        # PCA 3D\n",
    "        pca3 = PCA(n_components=3, random_state=0)\n",
    "        components_3d = pca3.fit_transform(X_dense)\n",
    "        fig_pca_3d = px.scatter_3d(pd.DataFrame(components_3d), x=0, y=1, z=2, color=df_y, title='ACP (3D)',\n",
    "                                   labels={'0': 'PC 1', '1': 'PC 2', '2': 'PC 3'})\n",
    "        fig_pca_3d.show()\n",
    "\n",
    "        # TSNE 2D\n",
    "        tsne2d = TSNE(n_components=2, random_state=0)\n",
    "        tsne_proj_2d = tsne2d.fit_transform(X_dense)\n",
    "        fig_tsne_2d = px.scatter(pd.DataFrame(tsne_proj_2d), x=0, y=1, color=df_y, labels={'color': 'Label'})\n",
    "        fig_tsne_2d.update_layout(title='t-SNE (2D)')\n",
    "        fig_tsne_2d.show()\n",
    "\n",
    "        # TSNE 3D\n",
    "        tsne3d = TSNE(n_components=3, random_state=0)\n",
    "        tsne_proj_3d = tsne3d.fit_transform(X_dense)\n",
    "        fig_tsne_3d = px.scatter_3d(pd.DataFrame(tsne_proj_3d), x=0, y=1, z=2, color=df_y, labels={'color': 'Label'})\n",
    "        fig_tsne_3d.update_layout(title='t-SNE (3D)')\n",
    "        fig_tsne_3d.show()\n",
    "\n",
    "        # UMAP 2D\n",
    "        umap2d = UMAP(n_components=2, init='random', random_state=0)\n",
    "        umap_proj_2d = umap2d.fit_transform(X_dense)\n",
    "        fig_umap_2d = px.scatter(pd.DataFrame(umap_proj_2d), x=0, y=1, color=df_y, labels={'color': 'Label'})\n",
    "        fig_umap_2d.update_layout(title='UMAP (2D)')\n",
    "        fig_umap_2d.show()\n",
    "\n",
    "        # UMAP 3D\n",
    "        umap3d = UMAP(n_components=3, init='random', random_state=0)\n",
    "        umap_proj_3d = umap3d.fit_transform(X_dense)\n",
    "        fig_umap_3d = px.scatter_3d(pd.DataFrame(umap_proj_3d), x=0, y=1, z=2, color=df_y, labels={'color': 'Label'})\n",
    "        fig_umap_3d.update_layout(title='UMAP (3D)')\n",
    "        fig_umap_3d.show()\n",
    "\n",
    "def run_vis():\n",
    "    df = pd.read_csv('scitweets_export_tache2_60_40.tsv', sep='\\t')\n",
    "    pipeline = ModelPipeline2()\n",
    "\n",
    "    df_sci = pipeline.analyze_data(df)\n",
    "\n",
    "    df_sci = pipeline.create_label(df_sci)\n",
    "\n",
    "    df_sci, text_column = pipeline.preprocess_data(df_sci, use_advanced_cleaning=True)\n",
    "    \n",
    "    X_tfidf, X_full, vect = pipeline.vectorize_text(df_sci, use_cleaned=True)\n",
    "    \n",
    "    X_cleaned, _ = pipeline.extract_cleaned_features(X_tfidf, vect)\n",
    "    \n",
    "    y = df_sci[\"label\"]\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "    # Exemple d'utilisation apr√®s vectorisation\n",
    "    visualizer = DataVisualizer()\n",
    "    \n",
    "    # R√©duction SVD en 2D (sur X_final ou X_cleaned) pour fronti√®re de d√©cision simple\n",
    "    X_2D = visualizer.reduce_dimensions(X_cleaned, method=\"svd\")  # ou \"pca\"\n",
    "    \n",
    "    # Visualisation des fronti√®res, tracer la fronti√®re d‚Äôun mod√®le simple\n",
    "    visualizer.plot_decision_boundary(LogisticRegression(), X_2D, y, \"Logistic Regression\")\n",
    "    \n",
    "    # Plusieurs mod√®les d‚Äôun coup, Tracer 2x2 plusieurs mod√®les avec PCA\n",
    "    visualizer.plot_multiple_boundaries(X_cleaned, y)\n",
    "    \n",
    "    # Courbes interactives PCA/tSNE/UMAP en 2D/3D\n",
    "    visualizer.plot_dimensionality_reduction(X_cleaned, y)\n",
    "    \n",
    "    \n",
    "    # (optionnel) ROC si on a y_scores (sortie de .predict_proba ou .decision_function)\n",
    "    model = MLPClassifier(max_iter=300, random_state=42)\n",
    "    y_scores = cross_val_predict(model, X, y, cv=skf, method='predict_proba')[:, 1]\n",
    "    visualizer.plot_roc_curve(y, y_scores, model_name=\"MLP\")\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Multi-label Classification\n",
    "\n",
    "Pipeline for multi-label classification of scientific tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_kfold(X, Y, strat_col, class_weights, n_splits=5):\n",
    "    \"\"\"Perform k-fold cross-validation with improved pipeline\"\"\"\n",
    "    kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    metrics = {\n",
    "        'accuracy': [],\n",
    "        'precision_micro': [],\n",
    "        'recall_micro': [],\n",
    "        'f1_micro': [],\n",
    "        'precision_macro': [],\n",
    "        'recall_macro': [],\n",
    "        'f1_macro': []\n",
    "    }\n",
    "    \n",
    "    # For plotting\n",
    "    fold_metrics_history = []\n",
    "    \n",
    "    # Create improved TF-IDF vectorizer\n",
    "    print(\"Vectorizing text...\")\n",
    "    vectorizer = TfidfVectorizer(\n",
    "        ngram_range=(1, 3),     # Unigrams, bigrams, and trigrams\n",
    "        min_df=3,               # Remove very rare words\n",
    "        max_df=0.95,            # Remove very common words\n",
    "        strip_accents='unicode', # Handle French accents\n",
    "        sublinear_tf=True,      # Apply sublinear scaling\n",
    "        use_idf=True,           # Use inverse document frequency\n",
    "        lowercase=True\n",
    "    )\n",
    "    X_tfidf = vectorizer.fit_transform(X)\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(X_tfidf, strat_col), 1):\n",
    "        print(f\"\\nProcessing fold {fold}/{n_splits}...\")\n",
    "        \n",
    "        # Split data\n",
    "        X_train = X_tfidf[train_idx]\n",
    "        X_val = X_tfidf[val_idx]\n",
    "        Y_train = Y.iloc[train_idx]\n",
    "        Y_val = Y.iloc[val_idx]\n",
    "        \n",
    "        # Create a single base classifier\n",
    "        base_svc = LinearSVC(\n",
    "            random_state=42,\n",
    "            max_iter=2000,\n",
    "            dual=False,\n",
    "            C=1.0\n",
    "        )\n",
    "        \n",
    "        # Add probability calibration\n",
    "        clf = CalibratedClassifierCV(base_svc, cv=3)\n",
    "        \n",
    "        # Create multi-output classifier with the single base classifier\n",
    "        multi_clf = MultiOutputClassifier(clf, n_jobs=-1)\n",
    "        \n",
    "        # Train model\n",
    "        multi_clf.fit(X_train, Y_train)\n",
    "        \n",
    "        # Predict\n",
    "        Y_pred = multi_clf.predict(X_val)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        fold_metrics = {\n",
    "            'accuracy': accuracy_score(Y_val, Y_pred),\n",
    "            'precision_micro': precision_score(Y_val, Y_pred, average='micro'),\n",
    "            'recall_micro': recall_score(Y_val, Y_pred, average='micro'),\n",
    "            'f1_micro': f1_score(Y_val, Y_pred, average='micro'),\n",
    "            'precision_macro': precision_score(Y_val, Y_pred, average='macro'),\n",
    "            'recall_macro': recall_score(Y_val, Y_pred, average='macro'),\n",
    "            'f1_macro': f1_score(Y_val, Y_pred, average='macro')\n",
    "        }\n",
    "        \n",
    "        # Store metrics\n",
    "        for metric, value in fold_metrics.items():\n",
    "            metrics[metric].append(value)\n",
    "        fold_metrics_history.append(fold_metrics)\n",
    "        \n",
    "        # Print fold results\n",
    "        print(f\"\\nFold {fold} Results:\")\n",
    "        print(f\"Accuracy: {fold_metrics['accuracy']:.4f}\")\n",
    "        print(f\"F1 (micro): {fold_metrics['f1_micro']:.4f}\")\n",
    "        print(f\"F1 (macro): {fold_metrics['f1_macro']:.4f}\")\n",
    "        \n",
    "        # Print detailed classification report\n",
    "        print(\"\\nClassification Report:\")\n",
    "        print(classification_report(Y_val, Y_pred, target_names=label_cols))\n",
    "        \n",
    "        # Print label distribution\n",
    "        print(\"\\nPredicted label distribution in this fold:\")\n",
    "        for i, col in enumerate(Y_train.columns):\n",
    "            val_dist = np.bincount(Y_pred[:, i]) / len(Y_pred)\n",
    "            print(f\"\\n{col}:\")\n",
    "            print(f\"Distribution: {dict(enumerate(val_dist))}\")\n",
    "    \n",
    "    # Print overall results\n",
    "    print(\"\\n=== Overall Results ===\")\n",
    "    for metric, scores in metrics.items():\n",
    "        mean = np.mean(scores)\n",
    "        std = np.std(scores)\n",
    "        print(f\"{metric}: {mean:.4f} ¬± {std:.4f}\")\n",
    "    \n",
    "    # Plot metrics\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    metrics_df = pd.DataFrame(fold_metrics_history)\n",
    "    \n",
    "    for i, metric in enumerate(['accuracy', 'f1_micro', 'f1_macro']):\n",
    "        plt.subplot(1, 3, i+1)\n",
    "        plt.plot(range(1, n_splits + 1), metrics_df[metric], marker='o')\n",
    "        plt.title(f'{metric.capitalize()} across Folds')\n",
    "        plt.xlabel('Fold')\n",
    "        plt.ylabel('Score')\n",
    "        plt.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return metrics, metrics_df, vectorizer, multi_clf\n",
    "\n",
    "def run_task3():\n",
    "    \"\"\"Execute Task 3: Multi-label Classification\"\"\"\n",
    "    print(\"\\n=== Task 3: Multi-label Classification ===\")\n",
    "    \n",
    "    def basic_preprocess(text):\n",
    "        \"\"\"Minimal text preprocessing\"\"\"\n",
    "        text = str(text).lower()\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        text = re.sub(r'[^\\w\\s#@/:.]+', '', text)\n",
    "        return text.strip()\n",
    "\n",
    "    # Load data\n",
    "    print(\"\\nLoading data...\")\n",
    "    df = pd.read_csv(\"scitweets_export.tsv\", sep=\"\\t\")\n",
    "    \n",
    "    # Preprocess text\n",
    "    print(\"\\nPreprocessing text...\")\n",
    "    df['processed_text'] = df['text'].apply(basic_preprocess)\n",
    "    \n",
    "    # Prepare labels\n",
    "    label_cols = [\"scientific_claim\", \"scientific_reference\", \"scientific_context\"]\n",
    "    Y = df[label_cols].fillna(0).astype(int)\n",
    "    \n",
    "    # Calculate class weights\n",
    "    class_weights = []\n",
    "    for col in Y.columns:\n",
    "        counts = Counter(Y[col])\n",
    "        weight = {0: 1.0, 1: counts[0] / counts[1] * 1.5}\n",
    "        class_weights.append(weight)\n",
    "        \n",
    "    # Display stats\n",
    "    print(\"\\nLabel distribution and weights:\")\n",
    "    for col, weights in zip(label_cols, class_weights):\n",
    "        counts = Y[col].value_counts()\n",
    "        print(f\"\\n{col}:\")\n",
    "        print(f\"Class 0: {counts[0]} ({counts[0]/len(Y)*100:.1f}%)\")\n",
    "        print(f\"Class 1: {counts[1]} ({counts[1]/len(Y)*100:.1f}%)\")\n",
    "        print(f\"Weights: {weights}\")\n",
    "    \n",
    "    # Create stratification column\n",
    "    strat_col = Y.apply(lambda x: ''.join(x.astype(str)), axis=1)\n",
    "    \n",
    "    # Vectorize and train\n",
    "    print(\"\\n=== Starting K-Fold Cross-Validation ===\")\n",
    "    metrics, metrics_df, vectorizer, best_clf = evaluate_kfold(\n",
    "        df['processed_text'], Y, strat_col, class_weights, n_splits=5\n",
    "    )\n",
    "    \n",
    "    # Train final model\n",
    "    print(\"\\n=== Training Final Model on Full Dataset ===\")\n",
    "    X_full = vectorizer.transform(df['processed_text'])\n",
    "    \n",
    "    base_svc = LinearSVC(\n",
    "        random_state=42,\n",
    "        max_iter=2000,\n",
    "        dual=False,\n",
    "        C=1.0\n",
    "    )\n",
    "    \n",
    "    clf = CalibratedClassifierCV(base_svc, cv=3)\n",
    "    final_clf = MultiOutputClassifier(clf, n_jobs=-1)\n",
    "    final_clf.fit(X_full, Y)\n",
    "    \n",
    "    # Save model\n",
    "    print(\"\\nSaving model artifacts...\")\n",
    "    model_artifacts = {\n",
    "        'classifier': final_clf,\n",
    "        'vectorizer': vectorizer,\n",
    "        'class_weights': class_weights\n",
    "    }\n",
    "    joblib.dump(model_artifacts, \"svm_classifier_improved.joblib\")\n",
    "    \n",
    "    # Plot results\n",
    "    plt.figure(figsize=(15, 12))\n",
    "    \n",
    "    # Plot 1: Micro vs Macro metrics\n",
    "    plt.subplot(2, 1, 1)\n",
    "    metric_groups = ['macro', 'micro']\n",
    "    metrics_to_plot = ['precision', 'recall', 'f1']\n",
    "    \n",
    "    x = np.arange(len(metrics_to_plot))\n",
    "    width = 0.35\n",
    "    \n",
    "    for i, group in enumerate(metric_groups):\n",
    "        metric_values = [np.mean(metrics[f'{metric}_{group}']) for metric in metrics_to_plot]\n",
    "        metric_stds = [np.std(metrics[f'{metric}_{group}']) for metric in metrics_to_plot]\n",
    "        \n",
    "        bars = plt.bar(x + i*width, metric_values, width, yerr=metric_stds, capsize=5,\n",
    "                       label=f'{group.capitalize()} Average')\n",
    "        \n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                    f'{height:.3f}',\n",
    "                    ha='center', va='bottom')\n",
    "    \n",
    "    plt.title('Model Performance Metrics')\n",
    "    plt.xticks(x + width/2, metrics_to_plot)\n",
    "    plt.ylim(0, 1)\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 2: Metrics stability across folds\n",
    "    plt.subplot(2, 1, 2)\n",
    "    sns.boxplot(data=metrics_df[['accuracy', 'f1_micro', 'f1_macro']])\n",
    "    plt.title('Metrics Distribution Across Folds')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataVisualizer:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def reduce_dimensions(self, X, method=\"svd\"):\n",
    "        if method == \"svd\":\n",
    "            reducer = TruncatedSVD(n_components=2, random_state=42)\n",
    "        else:\n",
    "            reducer = PCA(n_components=2, random_state=42)\n",
    "\n",
    "        return reducer.fit_transform(X)\n",
    "\n",
    "    def plot_decision_boundary(self, model, X_2D, y, title):\n",
    "        h = .02\n",
    "        x_min, x_max = X_2D[:, 0].min() - 1, X_2D[:, 0].max() + 1\n",
    "        y_min, y_max = X_2D[:, 1].min() - 1, X_2D[:, 1].max() + 1\n",
    "        xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "\n",
    "        model.fit(X_2D, y)\n",
    "        try:\n",
    "            Z = model.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
    "        except Exception as e:\n",
    "            print(f\"Erreur: {e}\")\n",
    "            return\n",
    "\n",
    "        cmap_light = ListedColormap(['#FFCCCC', '#CCCCFF'])\n",
    "        cmap_bold = ListedColormap(['#FF0000', '#0000FF'])\n",
    "\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        plt.contourf(xx, yy, Z, cmap=cmap_light, alpha=0.3)\n",
    "        plt.scatter(X_2D[:, 0], X_2D[:, 1], c=y, cmap=cmap_bold, edgecolor='k', s=20)\n",
    "        plt.title(f\"Fronti√®re de d√©cision : {title}\")\n",
    "        plt.xlabel(\"Composante 1\")\n",
    "        plt.ylabel(\"Composante 2\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def plot_multiple_boundaries(self, X, y):\n",
    "        pca = PCA(n_components=2, random_state=42)\n",
    "        X_vis = pca.fit_transform(X.toarray())\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(X_vis)\n",
    "\n",
    "        classifiers = {\n",
    "            \"Logistic Regression\": LogisticRegression(),\n",
    "            \"Gaussian NB\": GaussianNB(),\n",
    "            \"KNN\": KNeighborsClassifier(),\n",
    "            \"SVM\": SVC()\n",
    "        }\n",
    "\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "        axes = axes.ravel()\n",
    "        colors = ['blue', 'orange']\n",
    "        markers = ['o', 's']\n",
    "\n",
    "        for idx, (name, clf) in enumerate(classifiers.items()):\n",
    "            clf.fit(X_scaled, y)\n",
    "            accuracy = clf.score(X_scaled, y)\n",
    "\n",
    "            DecisionBoundaryDisplay.from_estimator(\n",
    "                clf, X_scaled, cmap=plt.cm.Paired, response_method=\"predict\", alpha=0.8, ax=axes[idx]\n",
    "            )\n",
    "\n",
    "            for label, marker, color in zip([0, 1], markers, colors):\n",
    "                axes[idx].scatter(X_scaled[y == label][:, 0], X_scaled[y == label][:, 1],\n",
    "                                  c=color, marker=marker, edgecolor='k', label=f\"Classe {label}\" if idx == 0 else \"\")\n",
    "\n",
    "            axes[idx].set_title(f\"{name} (Accuracy: {accuracy:.2f})\", fontsize=12)\n",
    "            axes[idx].set_xlabel(\"PC1\")\n",
    "            axes[idx].set_ylabel(\"PC2\")\n",
    "\n",
    "        handles = [plt.Line2D([0], [0], marker=markers[i], color='w', markerfacecolor=colors[i], markeredgecolor='k', markersize=10, label=f\"Classe {i}\") for i in range(2)]\n",
    "        fig.legend(handles=handles, loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "        plt.tight_layout(rect=[0, 0, 0.85, 1])\n",
    "        plt.show()\n",
    "\n",
    "    def plot_roc_curve(self, y_true, y_scores, model_name=\"Model\"):\n",
    "        fpr, tpr, thresholds = roc_curve(y_true, y_scores)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.plot(fpr, tpr, marker='o', linestyle='-', color='blue', label=f'ROC curve (AUC = {roc_auc:.3f})')\n",
    "        plt.plot([0, 1], [0, 1], color='red', linestyle='--', label='Random classifier')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate (FPR)')\n",
    "        plt.ylabel('True Positive Rate (TPR)')\n",
    "        plt.title(f'ROC Curve - {model_name}')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "    def plot_dimensionality_reduction(self, X, y):\n",
    "        df_y = pd.Series(y).astype(str)\n",
    "        X_dense = X.toarray()\n",
    "\n",
    "        # PCA 2D\n",
    "        pca = PCA(n_components=2, random_state=0)\n",
    "        components_2d = pca.fit_transform(X_dense)\n",
    "        fig_pca_2d = px.scatter(pd.DataFrame(components_2d), x=0, y=1, color=df_y, labels={\"color\": \"Label\"})\n",
    "        fig_pca_2d.update_layout(title='ACP (2D)')\n",
    "        fig_pca_2d.show()\n",
    "\n",
    "        # PCA 3D\n",
    "        pca3 = PCA(n_components=3, random_state=0)\n",
    "        components_3d = pca3.fit_transform(X_dense)\n",
    "        fig_pca_3d = px.scatter_3d(pd.DataFrame(components_3d), x=0, y=1, z=2, color=df_y, title='ACP (3D)',\n",
    "                                   labels={'0': 'PC 1', '1': 'PC 2', '2': 'PC 3'})\n",
    "        fig_pca_3d.show()\n",
    "\n",
    "        # TSNE 2D\n",
    "        tsne2d = TSNE(n_components=2, random_state=0)\n",
    "        tsne_proj_2d = tsne2d.fit_transform(X_dense)\n",
    "        fig_tsne_2d = px.scatter(pd.DataFrame(tsne_proj_2d), x=0, y=1, color=df_y, labels={'color': 'Label'})\n",
    "        fig_tsne_2d.update_layout(title='t-SNE (2D)')\n",
    "        fig_tsne_2d.show()\n",
    "\n",
    "        # TSNE 3D\n",
    "        tsne3d = TSNE(n_components=3, random_state=0)\n",
    "        tsne_proj_3d = tsne3d.fit_transform(X_dense)\n",
    "        fig_tsne_3d = px.scatter_3d(pd.DataFrame(tsne_proj_3d), x=0, y=1, z=2, color=df_y, labels={'color': 'Label'})\n",
    "        fig_tsne_3d.update_layout(title='t-SNE (3D)')\n",
    "        fig_tsne_3d.show()\n",
    "\n",
    "        # UMAP 2D\n",
    "        umap2d = UMAP(n_components=2, init='random', random_state=0)\n",
    "        umap_proj_2d = umap2d.fit_transform(X_dense)\n",
    "        fig_umap_2d = px.scatter(pd.DataFrame(umap_proj_2d), x=0, y=1, color=df_y, labels={'color': 'Label'})\n",
    "        fig_umap_2d.update_layout(title='UMAP (2D)')\n",
    "        fig_umap_2d.show()\n",
    "\n",
    "        # UMAP 3D\n",
    "        umap3d = UMAP(n_components=3, init='random', random_state=0)\n",
    "        umap_proj_3d = umap3d.fit_transform(X_dense)\n",
    "        fig_umap_3d = px.scatter_3d(pd.DataFrame(umap_proj_3d), x=0, y=1, z=2, color=df_y, labels={'color': 'Label'})\n",
    "        fig_umap_3d.update_layout(title='UMAP (3D)')\n",
    "        fig_umap_3d.show()\n",
    "\n",
    "def run_visualization():\n",
    "    \"\"\"Execute visualization tasks\"\"\"\n",
    "    print(\"\\n=== Visualization Tasks ===\")\n",
    "    \n",
    "    # Load data\n",
    "    df = pd.read_csv(\"scitweets_export.tsv\", sep=\"\\t\")\n",
    "    \n",
    "    # Preprocess text\n",
    "    df['processed_text'] = df['text'].apply(lambda x: str(x).lower())\n",
    "    \n",
    "    # Prepare labels\n",
    "    label_cols = [\"scientific_claim\", \"scientific_reference\", \"scientific_context\"]\n",
    "    Y = df[label_cols].fillna(0).astype(int)\n",
    "    \n",
    "    # Vectorize text\n",
    "    vectorizer = TfidfVectorizer(\n",
    "        ngram_range=(1, 2),\n",
    "        min_df=3,\n",
    "        max_df=0.95,\n",
    "        strip_accents='unicode',\n",
    "        sublinear_tf=True,\n",
    "        use_idf=True,\n",
    "        lowercase=True\n",
    "    )\n",
    "    X_tfidf = vectorizer.fit_transform(df['processed_text'])\n",
    "    \n",
    "    # Initialize visualizer\n",
    "    visualizer = DataVisualizer()\n",
    "    \n",
    "    # Dimensionality reduction and plotting\n",
    "    X_2D = visualizer.reduce_dimensions(X_tfidf, method=\"svd\")\n",
    "    \n",
    "    # Plot decision boundaries for different classifiers\n",
    "    classifiers = {\n",
    "        \"Logistic Regression\": LogisticRegression(),\n",
    "        \"Gaussian NB\": GaussianNB(),\n",
    "        \"KNN\": KNeighborsClassifier(),\n",
    "        \"SVM\": SVC()\n",
    "    }\n",
    "    \n",
    "    for name, clf in classifiers.items():\n",
    "        visualizer.plot_decision_boundary(clf, X_2D, Y.values[:, 0], name)\n",
    "    \n",
    "    # Plot ROC curve for a specific model (e.g., Logistic Regression)\n",
    "    y_scores = classifiers[\"Logistic Regression\"].fit(X_tfidf, Y.values[:, 0]).predict_proba(X_tfidf)[:, 1]\n",
    "    visualizer.plot_roc_curve(Y.values[:, 0], y_scores, model_name=\"Logistic Regression\")\n",
    "    \n",
    "    # Plot dimensionality reduction results\n",
    "    visualizer.plot_dimensionality_reduction(X_tfidf, Y.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Execution\n",
    "\n",
    "Choose which task to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    while True:\n",
    "        print(\"\\nChoose a task to run:\")\n",
    "        print(\"1. Science Related Classification\")\n",
    "        print(\"2. CLAIM/REF vs CONTEXT Classification\")\n",
    "        print(\"3. Multi-label Classification\")\n",
    "        print(\"4. Exit\")\n",
    "        \n",
    "        choice = input(\"\\nEnter task number (1-4): \")\n",
    "        \n",
    "        if choice == '1':\n",
    "            run_task1()\n",
    "        elif choice == '2':\n",
    "            run_task2()\n",
    "            run_hyper()\n",
    "        elif choice == '3':\n",
    "            run_task3()\n",
    "        elif choice == '4':\n",
    "            print(\"\\nExiting...\")\n",
    "            break\n",
    "        elif choice == '5':\n",
    "            run_vis()\n",
    "        else:\n",
    "            print(\"\\nInvalid choice. Please enter a number between 1 and 4.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Choose a task to run:\n",
      "1. Science Related Classification\n",
      "2. CLAIM/REF vs CONTEXT Classification\n",
      "3. Multi-label Classification\n",
      "4. Exit\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
